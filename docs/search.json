[
  {
    "objectID": "hyperparameters.html",
    "href": "hyperparameters.html",
    "title": "Lab 8: Hyperparameters",
    "section": "",
    "text": "Initial Packages\n\nlibrary(tidyverse)\n\nWarning: package 'readr' was built under R version 4.4.3\n\n\nWarning: package 'purrr' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.4.3\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.4.0     ✔ tune         1.3.0\n✔ infer        1.0.7     ✔ workflows    1.2.0\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.0     ✔ yardstick    1.3.2\n✔ recipes      1.1.1     \n\n\nWarning: package 'broom' was built under R version 4.4.3\n\n\nWarning: package 'dials' was built under R version 4.4.3\n\n\nWarning: package 'parsnip' was built under R version 4.4.3\n\n\nWarning: package 'recipes' was built under R version 4.4.3\n\n\nWarning: package 'tune' was built under R version 4.4.3\n\n\nWarning: package 'workflows' was built under R version 4.4.3\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\nlibrary(powerjoin)\n\nWarning: package 'powerjoin' was built under R version 4.4.3\n\nlibrary(readr)\nlibrary(skimr)\n\nWarning: package 'skimr' was built under R version 4.4.3\n\nlibrary(visdat)\n\nWarning: package 'visdat' was built under R version 4.4.3\n\nlibrary(ggpubr)\n\nWarning: package 'ggpubr' was built under R version 4.4.3\n\nlibrary(patchwork)\n\nWarning: package 'patchwork' was built under R version 4.4.3\n\nlibrary(glue)\nlibrary(baguette)\n\nWarning: package 'baguette' was built under R version 4.4.3\n\n\nData Retrieval\n\nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\n\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n\n\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\nlocal_files   &lt;- glue('data/camels_{types}.txt')\n\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE) \n\ncamels &lt;- power_full_join(camels ,by = 'gauge_id')\n\nData Cleaning\n\nvis_dat(camels)\n\n\n\n\n\n\n\nvis_miss(camels, cluster = TRUE)\n\n\n\n\n\n\n\n\n\ncamels_clean &lt;- camels %&gt;%\n  drop_na()\n\n\nnames(camels_clean)\n\n [1] \"gauge_id\"             \"p_mean\"               \"pet_mean\"            \n [4] \"p_seasonality\"        \"frac_snow\"            \"aridity\"             \n [7] \"high_prec_freq\"       \"high_prec_dur\"        \"high_prec_timing\"    \n[10] \"low_prec_freq\"        \"low_prec_dur\"         \"low_prec_timing\"     \n[13] \"geol_1st_class\"       \"glim_1st_class_frac\"  \"geol_2nd_class\"      \n[16] \"glim_2nd_class_frac\"  \"carbonate_rocks_frac\" \"geol_porostiy\"       \n[19] \"geol_permeability\"    \"soil_depth_pelletier\" \"soil_depth_statsgo\"  \n[22] \"soil_porosity\"        \"soil_conductivity\"    \"max_water_content\"   \n[25] \"sand_frac\"            \"silt_frac\"            \"clay_frac\"           \n[28] \"water_frac\"           \"organic_frac\"         \"other_frac\"          \n[31] \"gauge_lat\"            \"gauge_lon\"            \"elev_mean\"           \n[34] \"slope_mean\"           \"area_gages2\"          \"area_geospa_fabric\"  \n[37] \"frac_forest\"          \"lai_max\"              \"lai_diff\"            \n[40] \"gvf_max\"              \"gvf_diff\"             \"dom_land_cover_frac\" \n[43] \"dom_land_cover\"       \"root_depth_50\"        \"root_depth_99\"       \n[46] \"q_mean\"               \"runoff_ratio\"         \"slope_fdc\"           \n[49] \"baseflow_index\"       \"stream_elas\"          \"q5\"                  \n[52] \"q95\"                  \"high_q_freq\"          \"high_q_dur\"          \n[55] \"low_q_freq\"           \"low_q_dur\"            \"zero_q_freq\"         \n[58] \"hfd_mean\"            \n\n\nData Splitting\n\nset.seed(10262004)\n\ncamels_split &lt;- initial_split(camels_clean, prop = 0.8)\ncamels_train &lt;- training(camels_split)\ncamels_test  &lt;- testing(camels_split)\n\nRecipe\n\nlibrary(recipes)\n\nlibrary(recipes)\n\ncamels_rec &lt;- recipe(q_mean ~ ., data = camels_train) %&gt;%\n  update_role(gauge_lat, gauge_lon, new_role = \"ID\") %&gt;% \n  step_rm(gauge_id) %&gt;% \n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%  \n  step_impute_mean(all_numeric_predictors()) \n\n#I was having a ton of errors so this was the fix that chatgpt gave me\n\nResampling\n\nset.seed(10262004) \n\ncamels_cv &lt;- vfold_cv(camels_train, v = 10)\n\nDefining Models\n\nnn_model &lt;- bag_mlp() %&gt;%\n  set_engine(\"nnet\") %&gt;%\n  set_mode(\"regression\")\n\nrf_model &lt;- rand_forest() %&gt;%\n  set_engine(\"randomForest\") %&gt;%\n  set_mode(\"regression\")\n\nxgb_model &lt;- boost_tree() %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"regression\")\n\n\nwf_set &lt;- workflow_set(\n  list(camels_rec),  \n  list(nn_model, rf_model, xgb_model),  \n  cross = TRUE  \n)\n\nwf_results &lt;- wf_set %&gt;%\n  workflow_map(\n    \"fit_resamples\", \n    resamples = camels_cv,\n    control = control_grid(save_pred = TRUE)\n  )\n\n→ A | warning: ! There are new levels in `geol_1st_class`: \"Pyroclastics\".\n               ℹ Consider using step_novel() (`?recipes::step_novel()`) before `step_dummy()`\n                 to handle unseen values., ! There are new levels in `dom_land_cover`: \" Evergreen Broadleaf Forest\".\n               ℹ Consider using step_novel() (`?recipes::step_novel()`) before `step_dummy()`\n                 to handle unseen values.\n\n\nThere were issues with some computations   A: x1\n\n\n→ B | warning: ! There are new levels in `geol_1st_class`: \"Intermediate plutonic rocks\".\n               ℹ Consider using step_novel() (`?recipes::step_novel()`) before `step_dummy()`\n                 to handle unseen values.\n\n\nThere were issues with some computations   A: x1\nThere were issues with some computations   A: x1   B: x1\nThere were issues with some computations   A: x1   B: x1\n\n\nWarning: package 'randomForest' was built under R version 4.4.3\n\n\n→ A | warning: ! There are new levels in `geol_1st_class`: \"Pyroclastics\".\n               ℹ Consider using step_novel() (`?recipes::step_novel()`) before `step_dummy()`\n                 to handle unseen values., ! There are new levels in `dom_land_cover`: \" Evergreen Broadleaf Forest\".\n               ℹ Consider using step_novel() (`?recipes::step_novel()`) before `step_dummy()`\n                 to handle unseen values.\nThere were issues with some computations   A: x1\n→ B | warning: ! There are new levels in `geol_1st_class`: \"Intermediate plutonic rocks\".\n               ℹ Consider using step_novel() (`?recipes::step_novel()`) before `step_dummy()`\n                 to handle unseen values.\nThere were issues with some computations   A: x1\nThere were issues with some computations   A: x1   B: x1\nThere were issues with some computations   A: x1   B: x1\n\n\nWarning: package 'xgboost' was built under R version 4.4.3\n\n\n→ A | warning: ! There are new levels in `geol_1st_class`: \"Pyroclastics\".\n               ℹ Consider using step_novel() (`?recipes::step_novel()`) before `step_dummy()`\n                 to handle unseen values., ! There are new levels in `dom_land_cover`: \" Evergreen Broadleaf Forest\".\n               ℹ Consider using step_novel() (`?recipes::step_novel()`) before `step_dummy()`\n                 to handle unseen values.\n→ B | warning: ! There are new levels in `geol_1st_class`: \"Intermediate plutonic rocks\".\n               ℹ Consider using step_novel() (`?recipes::step_novel()`) before `step_dummy()`\n                 to handle unseen values.\n\nautoplot(wf_results)\n\n\n\n\n\n\n\n\nOut of the metrics, I am going to select XGBoost because it has a very high rsq and the lowest rmse. The model type is a boosted tree. The engine is xgboost. The mode is regression. I think its a good fit because the XGBoost model is robust, as it performs well with complex relationships present in the camels dataset.\nModel Testing\n\nxgb_model &lt;- boost_tree(\n  trees = tune(),           \n  tree_depth = tune()       \n) %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"regression\")\n\nxgb_workflow &lt;- workflow() %&gt;%\n  add_recipe(camels_rec) %&gt;%  \n  add_model(xgb_model)  \n\nxgb_grid &lt;- grid_regular(\n  trees(),\n  tree_depth(),\n  levels = 5\n)\n\n\nxgb_cv_resamples &lt;- vfold_cv(camels_train, v = 10)\n\n\nxgb_tune_results &lt;- tune_grid(\n  xgb_workflow,          \n  resamples = xgb_cv_resamples,\n  grid = xgb_grid,\n  metrics = metric_set(rmse, rsq)  \n)\n\n→ A | warning: ! There are new levels in `geol_1st_class`: \"Intermediate plutonic rocks\".\n               ℹ Consider using step_novel() (`?recipes::step_novel()`) before `step_dummy()`\n                 to handle unseen values.\n\n\nThere were issues with some computations   A: x1\n\n\nThere were issues with some computations   A: x3\n\n\nThere were issues with some computations   A: x5\n\n\n→ B | warning: ! There are new levels in `geol_1st_class`: \"Pyroclastics\".\n               ℹ Consider using step_novel() (`?recipes::step_novel()`) before `step_dummy()`\n                 to handle unseen values.\n\n\nThere were issues with some computations   A: x5\nThere were issues with some computations   A: x5   B: x1\nThere were issues with some computations   A: x5   B: x3\nThere were issues with some computations   A: x5   B: x5\n→ C | warning: ! There are new levels in `dom_land_cover`: \" Evergreen Broadleaf Forest\".\n               ℹ Consider using step_novel() (`?recipes::step_novel()`) before `step_dummy()`\n                 to handle unseen values.\nThere were issues with some computations   A: x5   B: x5\nThere were issues with some computations   A: x5   B: x5   C: x1\nThere were issues with some computations   A: x5   B: x5   C: x2\nThere were issues with some computations   A: x5   B: x5   C: x4\nThere were issues with some computations   A: x5   B: x5   C: x5\n\nxgb_tune_results\n\n# Tuning results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits           id     .metrics          .notes          \n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;            &lt;list&gt;          \n 1 &lt;split [364/41]&gt; Fold01 &lt;tibble [50 × 6]&gt; &lt;tibble [5 × 3]&gt;\n 2 &lt;split [364/41]&gt; Fold02 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt;\n 3 &lt;split [364/41]&gt; Fold03 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt;\n 4 &lt;split [364/41]&gt; Fold04 &lt;tibble [50 × 6]&gt; &lt;tibble [5 × 3]&gt;\n 5 &lt;split [364/41]&gt; Fold05 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt;\n 6 &lt;split [365/40]&gt; Fold06 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt;\n 7 &lt;split [365/40]&gt; Fold07 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt;\n 8 &lt;split [365/40]&gt; Fold08 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt;\n 9 &lt;split [365/40]&gt; Fold09 &lt;tibble [50 × 6]&gt; &lt;tibble [5 × 3]&gt;\n10 &lt;split [365/40]&gt; Fold10 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt;\n\nThere were issues with some computations:\n\n  - Warning(s) x5: ! There are new levels in `dom_land_cover`: \" Evergreen Broadleaf...\n  - Warning(s) x5: ! There are new levels in `geol_1st_class`: \"Intermediate plutoni...\n  - Warning(s) x5: ! There are new levels in `geol_1st_class`: \"Pyroclastics\". ℹ Con...\n\nRun `show_notes(.Last.tune.result)` for more information.\n\n\nHyperparameter Tuning\n\nxgb_tune_results &lt;- tune_grid(\n  xgb_workflow,          \n  resamples = xgb_cv_resamples,\n  grid = xgb_grid,\n  metrics = metric_set(rmse, rsq, mae)  \n)\n\n→ A | warning: ! There are new levels in `geol_1st_class`: \"Intermediate plutonic rocks\".\n               ℹ Consider using step_novel() (`?recipes::step_novel()`) before `step_dummy()`\n                 to handle unseen values.\n\n\nThere were issues with some computations   A: x1\n\n\nThere were issues with some computations   A: x3\n\n\nThere were issues with some computations   A: x5\n\n\n→ B | warning: ! There are new levels in `geol_1st_class`: \"Pyroclastics\".\n               ℹ Consider using step_novel() (`?recipes::step_novel()`) before `step_dummy()`\n                 to handle unseen values.\n\n\nThere were issues with some computations   A: x5\nThere were issues with some computations   A: x5   B: x1\nThere were issues with some computations   A: x5   B: x3\nThere were issues with some computations   A: x5   B: x5\n→ C | warning: ! There are new levels in `dom_land_cover`: \" Evergreen Broadleaf Forest\".\n               ℹ Consider using step_novel() (`?recipes::step_novel()`) before `step_dummy()`\n                 to handle unseen values.\nThere were issues with some computations   A: x5   B: x5\nThere were issues with some computations   A: x5   B: x5   C: x1\nThere were issues with some computations   A: x5   B: x5   C: x2\nThere were issues with some computations   A: x5   B: x5   C: x4\nThere were issues with some computations   A: x5   B: x5   C: x5\n\nautoplot(xgb_tune_results)\n\n\n\n\n\n\n\n\n\ntuned_metrics &lt;- collect_metrics(xgb_tune_results)\n\nhead(tuned_metrics)\n\n# A tibble: 6 × 8\n  trees tree_depth .metric .estimator  mean     n std_err .config              \n  &lt;int&gt;      &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n1     1          1 mae     standard   0.947    10 0.0423  Preprocessor1_Model01\n2     1          1 rmse    standard   1.51     10 0.0588  Preprocessor1_Model01\n3     1          1 rsq     standard   0.742    10 0.0316  Preprocessor1_Model01\n4   500          1 mae     standard   0.145    10 0.00831 Preprocessor1_Model02\n5   500          1 rmse    standard   0.228    10 0.0163  Preprocessor1_Model02\n6   500          1 rsq     standard   0.983    10 0.00225 Preprocessor1_Model02\n\nshow_best(xgb_tune_results)\n\nWarning in show_best(xgb_tune_results): No value of `metric` was given; \"rmse\"\nwill be used.\n\n\n# A tibble: 5 × 8\n  trees tree_depth .metric .estimator  mean     n std_err .config              \n  &lt;int&gt;      &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n1  2000          1 rmse    standard   0.218    10  0.0163 Preprocessor1_Model05\n2  1500          1 rmse    standard   0.218    10  0.0162 Preprocessor1_Model04\n3  1000          1 rmse    standard   0.220    10  0.0165 Preprocessor1_Model03\n4   500          1 rmse    standard   0.228    10  0.0163 Preprocessor1_Model02\n5   500          8 rmse    standard   0.230    10  0.0182 Preprocessor1_Model12\n\n\n\nbest_model_mae &lt;- show_best(xgb_tune_results, metric = \"mae\")\n\nbest_model_mae\n\n# A tibble: 5 × 8\n  trees tree_depth .metric .estimator  mean     n std_err .config              \n  &lt;int&gt;      &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n1  2000          4 mae     standard   0.122    10 0.00903 Preprocessor1_Model10\n2  1500          4 mae     standard   0.122    10 0.00903 Preprocessor1_Model09\n3   500          4 mae     standard   0.122    10 0.00903 Preprocessor1_Model07\n4  1000          4 mae     standard   0.122    10 0.00903 Preprocessor1_Model08\n5   500          8 mae     standard   0.125    10 0.00710 Preprocessor1_Model12\n\n\nThis is the combination of hyperparameters that gave the best value for mean absolute error. Hyperparameter Model Selection\n\nhp_best &lt;- select_best(xgb_tune_results, metric = \"mae\")\n\n\nhp_best\n\n# A tibble: 1 × 3\n  trees tree_depth .config              \n  &lt;int&gt;      &lt;int&gt; &lt;chr&gt;                \n1  2000          4 Preprocessor1_Model10\n\n\n\nxgb_final_wf &lt;- finalize_workflow(\n  xgb_workflow,\n  select_best(xgb_tune_results, metric = \"mae\")\n)\n\nxgb_final_wf\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_rm()\n• step_dummy()\n• step_impute_mean()\n\n── Model ───────────────────────────────────────────────────────────────────────\nBoosted Tree Model Specification (regression)\n\nMain Arguments:\n  trees = 2000\n  tree_depth = 4\n\nComputational engine: xgboost \n\n\n\nxgb_final_fit &lt;- last_fit(\n  xgb_final_wf,\n  split = camels_split\n)\n\n→ A | warning: ! There are new levels in `geol_1st_class`: \"Intermediate volcanic rocks\" and\n                 \"Basic plutonic rocks\".\n               ℹ Consider using step_novel() (`?recipes::step_novel()`) before `step_dummy()`\n                 to handle unseen values., ! There are new levels in `geol_2nd_class`: \"Pyroclastics\".\n               ℹ Consider using step_novel() (`?recipes::step_novel()`) before `step_dummy()`\n                 to handle unseen values., ! There are new levels in `dom_land_cover`: \" Barren or Sparsely Vegetated\".\n               ℹ Consider using step_novel() (`?recipes::step_novel()`) before `step_dummy()`\n                 to handle unseen values.\n\n\nThere were issues with some computations   A: x1\nThere were issues with some computations   A: x1\n\n\n\n\ncollect_metrics(xgb_final_fit)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       0.243 Preprocessor1_Model1\n2 rsq     standard       0.972 Preprocessor1_Model1\n\n\nGraph\n\nxgb_final_predictions &lt;- collect_predictions(xgb_final_fit)\n\n\nxgb_final_fit %&gt;%\n  collect_predictions() %&gt;%\n  ggplot(aes(x = .pred, y = q_mean)) +\n  geom_point(alpha = 0.6, color = \"#0073C2FF\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"darkred\") +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = \"gray40\") +\n  labs(\n    title = \"Predicted vs Actual Mean Daily Discharge using Baseflow Index\",\n    x = \"Predicted Mean Daily Discharge\",\n    y = \"Actual Mean Daily Discharge\"\n  ) +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nMapping\n\nfinal_fit_all &lt;- fit(xgb_final_wf, data = camels_clean)\n\n\n\nfull_preds &lt;- augment(final_fit_all, new_data = camels_clean)\n\nfull_preds &lt;- full_preds %&gt;%\n  mutate(residuals = (q_mean - .pred)^2)\n\n\n\nmap_pred &lt;- ggplot(full_preds, aes(x = gauge_lon, y = gauge_lat, color = .pred)) +\n  geom_point(size = 2) +\n  scale_color_viridis_c(option = \"plasma\") +\n  coord_fixed(1.3) +\n  labs(\n    title = \"Predicted q_mean Across CONUS\",\n    color = \"Prediction\"\n  ) +\n  theme_minimal()\n\nmap_resid &lt;- ggplot(full_preds, aes(x = gauge_lon, y = gauge_lat, color = residuals)) +\n  geom_point(size = 2) +\n  scale_color_viridis_c(option = \"inferno\") +\n  coord_fixed(1.3) +\n  labs(\n    title = \"Residuals (Squared Error) Across CONUS\",\n    color = \"Residuals\"\n  ) +\n  theme_minimal()\n\n\nlibrary(patchwork)\n\nmap_pred + map_resid +\n  plot_annotation(title = \"Model Predictions and Residuals Across the US\")"
  }
]